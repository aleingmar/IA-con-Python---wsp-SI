{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b92b6ef",
   "metadata": {},
   "source": [
    "# Práctica de redes neuronales con Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72a6da39",
   "metadata": {},
   "source": [
    "### Sistemas Inteligentes\n",
    "### Grado en Ingeniería de la salud\n",
    "### Universidad de Sevilla"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "341013f8",
   "metadata": {},
   "source": [
    "[Keras](https://keras.io/) es una biblioteca de Python que proporciona una interfaz amigable, modular y extensible para experimentar con redes neuronales. Actualmente Keras se desarrolla como parte de [TensorFlow](https://www.tensorflow.org/), la plataforma para aprendizaje automático de Google. Esto significa que para poder usar Keras se debe instalar el paquete `tensorflow` de Python. En esta práctica también se hará uso de los paquetes `numpy`, `pandas` y `sklearn`, que se deberán tener instalados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40c5cebb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\user\\anaconda3\\lib\\site-packages (2.11.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.11.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (2.11.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (21.3)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (2.2.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: tensorboard<2.12,>=2.11 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (2.11.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (3.7.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (0.29.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (63.4.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (4.3.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.21.5)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.3.0)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (3.19.6)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (14.0.6)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.51.1)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (23.1.4)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (0.4.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.12,>=2.11.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (2.11.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: keras<2.12,>=2.11.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (2.11.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.11.0->tensorflow) (0.37.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2.0.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2.28.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (3.3.4)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2.15.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (1.8.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from packaging->tensorflow-intel==2.11.0->tensorflow) (3.0.9)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (5.2.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\user\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2022.9.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (3.3)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (1.26.11)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\user\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (3.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a3e4da",
   "metadata": {},
   "source": [
    "Trabajar con redes neuronales implica el manejo de números [pseudoaleatorios](https://es.wikipedia.org/wiki/N%C3%BAmero_pseudoaleatorio). Para que este documento sea reproducible es necesario, por tanto, establecer una semilla inicial para el generador de esos números."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "210caad2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-12 09:59:44.360138: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-12 09:59:44.511980: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-12-12 09:59:44.512001: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-12-12 09:59:45.323035: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-12-12 09:59:45.323146: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-12-12 09:59:45.323159: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import random as tensorflow_random\n",
    "\n",
    "tensorflow_random.set_seed(394867)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e86ae56",
   "metadata": {},
   "source": [
    "Importamos en primer lugar los paquetes que nos permitirán preprocesar los datos y dividirlos en subconjuntos de entrenamiento y prueba. También establecemos una semilla inicial para que estas operaciones sean reproducibles y fijamos el tamaño máximo que debe tener un array para que se muestre completo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f238e14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import pandas\n",
    "from sklearn import model_selection\n",
    "\n",
    "numpy.random.seed(43958734)\n",
    "numpy.set_printoptions(threshold=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d102994d",
   "metadata": {},
   "source": [
    "Finalmente importamos el paquete `keras`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9739575a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0782cbc",
   "metadata": {},
   "source": [
    "## Redes neuronales para tareas de regresión"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22a7d50d",
   "metadata": {},
   "source": [
    "El conjunto de datos [Gas Turbine CO and NOx Emission](http://archive.ics.uci.edu/ml/datasets/Gas+Turbine+CO+and+NOx+Emission+Data+Set) del repositorio [UCI](http://archive.ics.uci.edu/ml/index.html) contiene las siguientes medidas, agregadas por hora y tomadas desde el 1 de enero de 2011 hasta el 31 de diciembre de 2015, de una turbina de gas localizada en la región noroccidental de Turquía:\n",
    "\n",
    "* AT: temperatura ambiental, en grados centígrados.\n",
    "* AP: presión ambiental, en milibares.\n",
    "* AH: humedad ambiental, en porcentaje.\n",
    "* AFDP: diferencia de presión en el filtro de aire, en milibares.\n",
    "* GTEP: presión de escape de la turbina de gas, en milibares.\n",
    "* TIT: temperatura de entrada de la turbina, en grados centígrados.\n",
    "* TAT: temperatura de salida de la turbina, en grados centígrados.\n",
    "* CDP: presión de descarga del compresor, en milibares.\n",
    "* TEY: rendimiento energético de la turbina, en megavatios por hora.\n",
    "* CO: emisiones de monóxido de carbono, en miligramos por metro cúbico.\n",
    "* NOX: emisiones de óxidos de nitrógeno, en miligramos por metro cúbico.\n",
    "\n",
    "Los datos se encuentran en el fichero `gas_turbine.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b88523d9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AT</th>\n",
       "      <th>AP</th>\n",
       "      <th>AH</th>\n",
       "      <th>AFDP</th>\n",
       "      <th>GTEP</th>\n",
       "      <th>TIT</th>\n",
       "      <th>TAT</th>\n",
       "      <th>CDP</th>\n",
       "      <th>TEY</th>\n",
       "      <th>CO</th>\n",
       "      <th>NOX</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.5878</td>\n",
       "      <td>1018.7</td>\n",
       "      <td>83.675</td>\n",
       "      <td>3.5758</td>\n",
       "      <td>23.979</td>\n",
       "      <td>1086.2</td>\n",
       "      <td>549.83</td>\n",
       "      <td>11.898</td>\n",
       "      <td>134.67</td>\n",
       "      <td>0.32663</td>\n",
       "      <td>81.952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.2932</td>\n",
       "      <td>1018.3</td>\n",
       "      <td>84.235</td>\n",
       "      <td>3.5709</td>\n",
       "      <td>23.951</td>\n",
       "      <td>1086.1</td>\n",
       "      <td>550.05</td>\n",
       "      <td>11.892</td>\n",
       "      <td>134.67</td>\n",
       "      <td>0.44784</td>\n",
       "      <td>82.377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.9045</td>\n",
       "      <td>1018.4</td>\n",
       "      <td>84.858</td>\n",
       "      <td>3.5828</td>\n",
       "      <td>23.990</td>\n",
       "      <td>1086.5</td>\n",
       "      <td>550.19</td>\n",
       "      <td>12.042</td>\n",
       "      <td>135.10</td>\n",
       "      <td>0.45144</td>\n",
       "      <td>83.776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.7436</td>\n",
       "      <td>1018.3</td>\n",
       "      <td>85.434</td>\n",
       "      <td>3.5808</td>\n",
       "      <td>23.911</td>\n",
       "      <td>1086.5</td>\n",
       "      <td>550.17</td>\n",
       "      <td>11.990</td>\n",
       "      <td>135.03</td>\n",
       "      <td>0.23107</td>\n",
       "      <td>82.505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.7516</td>\n",
       "      <td>1017.8</td>\n",
       "      <td>85.182</td>\n",
       "      <td>3.5781</td>\n",
       "      <td>23.917</td>\n",
       "      <td>1085.9</td>\n",
       "      <td>550.00</td>\n",
       "      <td>11.910</td>\n",
       "      <td>134.67</td>\n",
       "      <td>0.26747</td>\n",
       "      <td>82.028</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       AT      AP      AH    AFDP    GTEP     TIT     TAT     CDP     TEY  \\\n",
       "0  4.5878  1018.7  83.675  3.5758  23.979  1086.2  549.83  11.898  134.67   \n",
       "1  4.2932  1018.3  84.235  3.5709  23.951  1086.1  550.05  11.892  134.67   \n",
       "2  3.9045  1018.4  84.858  3.5828  23.990  1086.5  550.19  12.042  135.10   \n",
       "3  3.7436  1018.3  85.434  3.5808  23.911  1086.5  550.17  11.990  135.03   \n",
       "4  3.7516  1017.8  85.182  3.5781  23.917  1085.9  550.00  11.910  134.67   \n",
       "\n",
       "        CO     NOX  \n",
       "0  0.32663  81.952  \n",
       "1  0.44784  82.377  \n",
       "2  0.45144  83.776  \n",
       "3  0.23107  82.505  \n",
       "4  0.26747  82.028  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gas_turbine = pandas.read_csv(\"gas_turbine.csv\")\n",
    "gas_turbine.head()\n",
    "#gas_turbine.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e33eccd5",
   "metadata": {},
   "source": [
    "Se plantea el problema de predecir el rendimiento energético de la turbina a partir de las medidas ambientales (AT, AP y AH) y de las medidas de los sensores de la turbina (AFDP, GTEP, TIT, TAT, CDP). Obsérvese que se trata de un problema de regresión, puesto que la variable objetivo es una variable continua."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c889858",
   "metadata": {},
   "source": [
    "En primer lugar, seleccionamos por un lado las variables predictoras y por otro lado la variable respuesta. En ambos casos transformamos los resultados a un array de NumPy, ya que ese tipo de dato es compatible con Keras mientras que los marcos de datos de Pandas no lo son."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "140e6b1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   4.5878 1018.7      83.675  ... 1086.2     549.83     11.898 ]\n",
      " [   4.2932 1018.3      84.235  ... 1086.1     550.05     11.892 ]\n",
      " [   3.9045 1018.4      84.858  ... 1086.5     550.19     12.042 ]\n",
      " ...\n",
      " [   5.482  1028.5      95.219  ... 1038.      543.48     10.462 ]\n",
      " [   5.8837 1028.7      94.2    ... 1076.9     550.11     11.771 ]\n",
      " [   6.0392 1028.8      94.547  ... 1067.9     548.23     11.462 ]]\n"
     ]
    }
   ],
   "source": [
    "atributos = gas_turbine.loc[:, 'AT':'CDP']\n",
    "atributos = atributos.to_numpy()\n",
    "print(atributos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fba9f550",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[134.67 134.67 135.1  ... 107.81 131.41 125.41]\n"
     ]
    }
   ],
   "source": [
    "objetivo = gas_turbine['TEY']\n",
    "objetivo = objetivo.to_numpy()\n",
    "print(objetivo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89c79cb6",
   "metadata": {},
   "source": [
    "A continuación construimos los subconjuntos de entrenamiento y prueba para la construcción y evaluación de redes neuronales mediante aprendizaje supervisado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9152db5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "(atributos_entrenamiento, atributos_prueba,\n",
    " objetivo_entrenamiento, objetivo_prueba) = model_selection.train_test_split(\n",
    "    atributos, objetivo, test_size=.33)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f5230f",
   "metadata": {},
   "source": [
    "Estamos ya en condiciones de construir una red neuronal que nos permita abordar el problema."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "063ab0dc",
   "metadata": {},
   "source": [
    "Keras admite dos aproximaciones a la hora de construir una red neuronal: el modelo funcional, más flexible, y el modelo secuencial, más simple y el cual será el que usaremos en esta práctica."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd3f0b53",
   "metadata": {},
   "source": [
    "En el modelo secuencial se construye una red neuronal capa a capa, comenzando por la capa de entrada y continuando con el resto de capas hasta la última, que será la capa de salida.\n",
    "\n",
    "La capa de entrada se construye como instancia de la clase `Input`, indicando la forma de la entrada, que puede ser un array con cualquier número de dimensiones. En nuestro caso la entrada será un array unidimensional con los valores de los atributos, pero podría ser por ejemplo una imagen bidimensional, etcétera.\n",
    "\n",
    "Para construir una red neuronal con alimentación hacia adelante, en el que las capas están totalmente conectadas, hay que añadir instancias de la clase `layers.Dense`, indicando la cantidad de neuronas y la función de activación (por defecto, la identidad)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84eb7d87",
   "metadata": {},
   "source": [
    "Por ejemplo, podemos construir una red neuronal con ocho neuronas de entrada, una por cada atributo, y una neurona de salida, que proporcione el rendimiento energético predicho, de la siguiente manera:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f83b92b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-12 09:59:47.184537: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-12-12 09:59:47.184646: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2022-12-12 09:59:47.184724: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2022-12-12 09:59:47.184798: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2022-12-12 09:59:47.184870: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory\n",
      "2022-12-12 09:59:47.184939: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2022-12-12 09:59:47.185011: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2022-12-12 09:59:47.185082: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2022-12-12 09:59:47.185098: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2022-12-12 09:59:47.185518: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "red_turbina = keras.Sequential()\n",
    "red_turbina.add(keras.Input(shape=(8,)))\n",
    "red_turbina.add(keras.layers.Dense(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "260daea8",
   "metadata": {},
   "source": [
    "El método `summary` nos muestra la estructura de la red, indicando para cada capa la forma de su salida y cuántos parámetros posee. La capa de entrada no se muestra, ya que no posee parámetros. La primera dimensión en la forma de la salida de cada capa indica el tamaño de los lotes (de los que hablaremos posteriormente) y si su valor es `None` quiere decir que se determinará posteriormente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6f83f6e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9\n",
      "Trainable params: 9\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "red_turbina.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ba1cc85",
   "metadata": {},
   "source": [
    "Se observa cómo la red neuronal posee una única capa (aparte de la de entrada) que proporciona como salida un array bidimensional None x 1 (es decir, para cada ejemplo proporciona un valor) y 9 parámetros (el peso de la conexión de cada entrada con la neurona de la capa más el sesgo de la neurona) entrenables (la red los aprenderá mediante el algoritmo de entrenamiento)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83c86fc8",
   "metadata": {},
   "source": [
    "Los pesos y sesgos de la red se guardan en el atributo `weights` (son los arrays asociados al argumento numpy en la estructura de datos guardada en ese atributo)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2281bf95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'dense/kernel:0' shape=(8, 1) dtype=float32, numpy=\n",
       " array([[ 0.48478258],\n",
       "        [ 0.23702323],\n",
       "        [ 0.34562147],\n",
       "        [-0.7070208 ],\n",
       "        [ 0.23453188],\n",
       "        [-0.65631664],\n",
       "        [-0.5645554 ],\n",
       "        [ 0.6873833 ]], dtype=float32)>,\n",
       " <tf.Variable 'dense/bias:0' shape=(1,) dtype=float32, numpy=array([0.], dtype=float32)>]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "red_turbina.weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f998d1",
   "metadata": {},
   "source": [
    "Si le pedimos a la red que prediga el rendimiento energético de los cinco primeros ejemplos del conjunto de datos, se obtendrán valores muy distintos de los correctos mostrados anteriormente, ya que todavía no se ha entrenado la red."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c0a5b618",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 64ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-739.42694],\n",
       "       [-739.5368 ],\n",
       "       [-739.7239 ],\n",
       "       [-739.66815],\n",
       "       [-739.4318 ]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "red_turbina.predict(gas_turbine.iloc[0:5, 0:8].to_numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a44025a4",
   "metadata": {},
   "source": [
    "Para entrenar una red neuronal hay que compilarla primero, estableciendo el algoritmo de aprendizaje (*optimizer*) y la función de pérdida (*loss*) a minimizar. Lo más cercano a lo explicado en clase es usar el error cuadrático medio (Keras no tiene implementada la suma de los errores cuadráticos, pero la minimización de ambas funciones es equivalente) y el algoritmo del descenso estocástico por el gradiente (*stochastic gradient descent*, SGD).\n",
    "\n",
    "El descenso estocástico por el gradiente es el algoritmo de retropropagación, pero en lugar de actualizar los pesos tras procesar todos los ejemplos de entrenamiento lo hace tras procesar un subconjunto de ellos cada vez. Cada uno de estos subconjuntos se llama un lote (*batch*). Los lotes se construyen repartiendo aleatoriamente los ejemplos de entrenamiento y cuando se han considerado todos los lotes (y, en consecuencia, todos los ejemplos) se dice que ha transcurrido una época (*epoch*)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1b3a6fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "red_turbina.compile(optimizer='SGD', loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3509007f",
   "metadata": {},
   "source": [
    "Por defecto se usa un factor de aprendizaje igual a 0.01. Solo falta, entonces, proporcionar los ejemplos de entrenamiento junto con la salida esperada para cada uno de ellos, el tamaño de los lotes y el número de épocas a entrenar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fe90c802",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "97/97 [==============================] - 0s 934us/step - loss: nan \n",
      "Epoch 2/10\n",
      "97/97 [==============================] - 0s 847us/step - loss: nan\n",
      "Epoch 3/10\n",
      "97/97 [==============================] - 0s 848us/step - loss: nan\n",
      "Epoch 4/10\n",
      "97/97 [==============================] - 0s 886us/step - loss: nan\n",
      "Epoch 5/10\n",
      "97/97 [==============================] - 0s 864us/step - loss: nan\n",
      "Epoch 6/10\n",
      "97/97 [==============================] - 0s 852us/step - loss: nan\n",
      "Epoch 7/10\n",
      "97/97 [==============================] - 0s 886us/step - loss: nan\n",
      "Epoch 8/10\n",
      "97/97 [==============================] - 0s 832us/step - loss: nan\n",
      "Epoch 9/10\n",
      "97/97 [==============================] - 0s 822us/step - loss: nan\n",
      "Epoch 10/10\n",
      "97/97 [==============================] - 0s 830us/step - loss: nan\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fdf803ba7c0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "red_turbina.fit(atributos_entrenamiento, objetivo_entrenamiento,\n",
    "                batch_size=256, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd3af792",
   "metadata": {},
   "source": [
    "El entrenamiento ha fallado, ya que se han producido desbordamientos numéricos al calcular la función de pérdida (nan quiere decir *not a number*). Los motivos de que se produzca esta circunstancia pueden ser múltiples y, a veces, difíciles de determinar. En este caso el problema se encuentra en que proporcionamos los valores en bruto de los atributos, cuando lo recomendable es que los valores que reciban como entrada las neuronas sean cercanos a cero.\n",
    "\n",
    "Es necesario, pues, introducir tras la capa de entrada una capa de normalización como por ejemplo la disponible en Keras para tipificar las variables (a cada variable se le resta su media y se divide por su desviación típica). Los parámetros de esta capa de normalización deben ajustarse a partir únicamente de los datos de entrenamiento, lo que se hace mediante el método `adapt`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "90cc8443",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizador = keras.layers.experimental.preprocessing.Normalization()\n",
    "normalizador.adapt(atributos_entrenamiento)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b35d4ecb",
   "metadata": {},
   "source": [
    "Podemos comprobar como todos los atributos de entrenamiento tienen media y varianza aproximadamente 0 y 1, respectivamente, al ser normalizados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5999cf3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.6957632e-06 -2.6569342e-05 -1.0380697e-05  5.7639295e-07\n",
      "  2.5071442e-06  7.2057173e-06  8.9993846e-05 -3.1143845e-06]\n",
      "[1.0000004  1.0000004  1.0000049  1.000001   0.9999952  0.99995697\n",
      " 0.99999523 1.0000012 ]\n"
     ]
    }
   ],
   "source": [
    "print(numpy.mean(normalizador(atributos_entrenamiento), axis=0))\n",
    "print(numpy.var(normalizador(atributos_entrenamiento), axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49065f55",
   "metadata": {},
   "source": [
    "Al introducir en la red esa capa de normalización justo tras la capa de entrada, todos los datos que se proporcionen como entrada a la red se tipificarán usando las medias y desviaciones típicas calculadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "29744d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "red_turbina = keras.Sequential()\n",
    "red_turbina.add(keras.Input(shape=(8,)))\n",
    "red_turbina.add(normalizador)\n",
    "red_turbina.add(keras.layers.Dense(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83387f95",
   "metadata": {},
   "source": [
    "Se puede comprobar que los parámetros de esa capa de normalización no son entrenables, es decir, no se modificarán al aplicar a la red el algoritmo de descenso estocástico por el gradiente (la capa de normalización tiene 17 parámetros en total porque guarda la media y la desviación típica de cada uno de los ocho atributos y, además, la cantidad total de ejemplos a partir de los cuales se han calculado)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "72de28b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " normalization (Normalizatio  (None, 8)                17        \n",
      " n)                                                              \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 26\n",
      "Trainable params: 9\n",
      "Non-trainable params: 17\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "red_turbina.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dada913",
   "metadata": {},
   "source": [
    "Como se ha vuelto a construir la red desde cero, también hay que volverla a compilar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3bf206c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "red_turbina.compile(optimizer='SGD', loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d4661d",
   "metadata": {},
   "source": [
    "Ahora la red ya entrena sin problema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2825104c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "97/97 [==============================] - 0s 974us/step - loss: 4611.4688\n",
      "Epoch 2/10\n",
      "97/97 [==============================] - 0s 968us/step - loss: 93.6941\n",
      "Epoch 3/10\n",
      "97/97 [==============================] - 0s 873us/step - loss: 3.4680\n",
      "Epoch 4/10\n",
      "97/97 [==============================] - 0s 890us/step - loss: 1.5351\n",
      "Epoch 5/10\n",
      "97/97 [==============================] - 0s 924us/step - loss: 1.4602\n",
      "Epoch 6/10\n",
      "97/97 [==============================] - 0s 894us/step - loss: 1.4407\n",
      "Epoch 7/10\n",
      "97/97 [==============================] - 0s 905us/step - loss: 1.4256\n",
      "Epoch 8/10\n",
      "97/97 [==============================] - 0s 864us/step - loss: 1.4121\n",
      "Epoch 9/10\n",
      "97/97 [==============================] - 0s 876us/step - loss: 1.3991\n",
      "Epoch 10/10\n",
      "97/97 [==============================] - 0s 878us/step - loss: 1.3863\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fdf8018c880>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "red_turbina.fit(atributos_entrenamiento, objetivo_entrenamiento,\n",
    "               batch_size=256, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5917a709",
   "metadata": {},
   "source": [
    "Para comprobar el comportamiento de la red sobre los datos de prueba basta usar el método `evaluate`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0f230dc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "379/379 [==============================] - 0s 815us/step - loss: 1.3453\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.3452847003936768"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "red_turbina.evaluate(atributos_prueba, objetivo_prueba)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dea2a08",
   "metadata": {},
   "source": [
    "Una forma de tratar de mejorar el rendimiento de la red neuronal es aumentar el número de épocas de entrenamiento. Esto, aparte del obvio coste en tiempo que supone, no garantiza que el algoritmo de entrenamiento no se quede atascado en un mínimo local de la función de pérdida, sin llegar a aproximarse nunca al mínimo global.\n",
    "\n",
    "Otra vía para conseguir una red neuronal con mejor rendimiento es modificar la estructura de la misma. Por ejemplo, en el caso que nos ocupa, podemos probar a incluir una capa oculta de la que se ha elegido, de forma arbitraria, que tenga 10 neuronas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b98b1fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "red_turbina = keras.Sequential()\n",
    "red_turbina.add(keras.Input(shape=(8,)))\n",
    "red_turbina.add(normalizador)\n",
    "red_turbina.add(keras.layers.Dense(10))\n",
    "red_turbina.add(keras.layers.Dense(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a30e87f7",
   "metadata": {},
   "source": [
    "Esta red tiene 101 parámetros entrenables, que provienen de los 8x10 pesos más 10 sesgos de las neuronas de la capa oculta más los 10 pesos y el sesgo de la neurona de la capa de salida. También tiene 17 parámetros no entrenables, que provienen de la capa de normalización."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ec4ed661",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " normalization (Normalizatio  (None, 8)                17        \n",
      " n)                                                              \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                90        \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 118\n",
      "Trainable params: 101\n",
      "Non-trainable params: 17\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "red_turbina.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1611a557",
   "metadata": {},
   "source": [
    "Al compilar la red se puede indicar también que, aparte de la función de pérdida, se calculan otras métricas adecuadas. Por ejemplo, el error absoluto medio (es decir, la media de las diferencias en valor absoluto entre los valores predichos y los valores correctos) es una métrica adecuada para una tarea de regresión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b70707dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "red_turbina.compile(optimizer='SGD', loss='mean_squared_error',\n",
    "                    metrics=['mean_absolute_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "48a68b47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "97/97 [==============================] - 0s 959us/step - loss: nan - mean_absolute_error: nan      \n",
      "Epoch 2/10\n",
      "97/97 [==============================] - 0s 917us/step - loss: nan - mean_absolute_error: nan\n",
      "Epoch 3/10\n",
      "97/97 [==============================] - 0s 1ms/step - loss: nan - mean_absolute_error: nan\n",
      "Epoch 4/10\n",
      "97/97 [==============================] - 0s 1ms/step - loss: nan - mean_absolute_error: nan\n",
      "Epoch 5/10\n",
      "97/97 [==============================] - 0s 1ms/step - loss: nan - mean_absolute_error: nan\n",
      "Epoch 6/10\n",
      "97/97 [==============================] - 0s 1ms/step - loss: nan - mean_absolute_error: nan\n",
      "Epoch 7/10\n",
      "97/97 [==============================] - 0s 1ms/step - loss: nan - mean_absolute_error: nan\n",
      "Epoch 8/10\n",
      "97/97 [==============================] - 0s 1ms/step - loss: nan - mean_absolute_error: nan\n",
      "Epoch 9/10\n",
      "97/97 [==============================] - 0s 1ms/step - loss: nan - mean_absolute_error: nan\n",
      "Epoch 10/10\n",
      "97/97 [==============================] - 0s 1ms/step - loss: nan - mean_absolute_error: nan\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fdf800639d0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "red_turbina.fit(atributos_entrenamiento, objetivo_entrenamiento,\n",
    "               batch_size=256, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b4e5392",
   "metadata": {},
   "source": [
    "De nuevo se han producido desbordamientos en el cálculo de la función de pérdida. En este caso es debido a que las neuronas de la capa oculta tienen como función de activación a la función identidad (la función de activación por defecto). Por lo tanto, aunque ellas sí reciben las entradas normalizadas, los valores que devuelven, y que son las que recibe la neurona de la capa de salida, pueden alejarse bastante del valor cero. Si establecemos como función de activación de las neuronas de la capa oculta a la función sigmoide, esta normalizará al intervalo (0, 1) los valores que devuelven esas neuronas y la red se podrá entrenar sin problema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "68dca87e",
   "metadata": {},
   "outputs": [],
   "source": [
    "red_turbina = keras.Sequential()\n",
    "red_turbina.add(keras.Input(shape=(8,)))\n",
    "red_turbina.add(normalizador)\n",
    "red_turbina.add(keras.layers.Dense(10, activation='sigmoid'))\n",
    "red_turbina.add(keras.layers.Dense(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "536a946c",
   "metadata": {},
   "source": [
    "Al compilar la red se pueden cambiar los parámetros de los distintos argumentos proporcionando, en lugar del nombre, una instancia de la clase que lo implementa. Por ejemplo, para establecer el factor de aprendizaje, en lugar de proporcionar el nombre `'SGD'` para indicar descenso estocástico por el gradiente como optimizador hay que proporcionar una instancia de la clase `SGD` que lo implementa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d40da4a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "red_turbina.compile(optimizer=keras.optimizers.SGD(learning_rate=0.02), loss='mean_squared_error',\n",
    "                    metrics=['mean_absolute_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "95e999dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "97/97 [==============================] - 0s 1ms/step - loss: 473.1885 - mean_absolute_error: 7.7159\n",
      "Epoch 2/10\n",
      "97/97 [==============================] - 0s 1ms/step - loss: 3.7997 - mean_absolute_error: 1.2718\n",
      "Epoch 3/10\n",
      "97/97 [==============================] - 0s 1ms/step - loss: 1.9800 - mean_absolute_error: 0.9848\n",
      "Epoch 4/10\n",
      "97/97 [==============================] - 0s 1ms/step - loss: 1.4902 - mean_absolute_error: 0.8836\n",
      "Epoch 5/10\n",
      "97/97 [==============================] - 0s 1ms/step - loss: 1.2683 - mean_absolute_error: 0.8317\n",
      "Epoch 6/10\n",
      "97/97 [==============================] - 0s 1ms/step - loss: 1.1194 - mean_absolute_error: 0.7918\n",
      "Epoch 7/10\n",
      "97/97 [==============================] - 0s 1ms/step - loss: 1.0243 - mean_absolute_error: 0.7644\n",
      "Epoch 8/10\n",
      "97/97 [==============================] - 0s 1ms/step - loss: 1.0262 - mean_absolute_error: 0.7690\n",
      "Epoch 9/10\n",
      "97/97 [==============================] - 0s 1ms/step - loss: 0.9161 - mean_absolute_error: 0.7286\n",
      "Epoch 10/10\n",
      "97/97 [==============================] - 0s 1ms/step - loss: 0.9327 - mean_absolute_error: 0.7360\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fdf800b88b0>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "red_turbina.fit(atributos_entrenamiento, objetivo_entrenamiento,\n",
    "               batch_size=256, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1ae1ff73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "379/379 [==============================] - 0s 861us/step - loss: 0.7964 - mean_absolute_error: 0.6850\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7964341640472412, 0.6850011348724365]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "red_turbina.evaluate(atributos_prueba, objetivo_prueba)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50f4c0cf",
   "metadata": {},
   "source": [
    "Se obtiene un error sobre el conjunto de prueba menor que el obtenido con la red sin capa oculta."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20d4db4b",
   "metadata": {},
   "source": [
    "### **Ejercicio 1**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4616a39c",
   "metadata": {},
   "source": [
    "Se plantea el problema de predecir **a la vez** el rendimiento energético de la turbina (TEY), las emisiones de monóxido de carbono (CO) y las emisiones de óxidos de nitrógeno (NOX) a partir de las medidas ambientales (AT, AP y AH) y de las medidas de los sensores de la turbina (AFDP, GTEP, TIT, TAT, CDP)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f209a47",
   "metadata": {},
   "source": [
    "Experimentar con diferentes arquitecturas de redes neuronales, que necesariamente deberán tener 3 neuronas en la capa de salida, y con diferentes configuraciones de entrenamiento para abordar el problema."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6433e35f",
   "metadata": {},
   "source": [
    "El objetivo último es construir una red neuronal con un error absoluto medio sobre el conjunto de prueba de alrededor de 1.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd2673b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5d5ef61d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Redes neuronales para tareas de clasificación"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2314c583",
   "metadata": {},
   "source": [
    "*Iris* es un conjunto de datos multivariante que se ha estudiado exhaustivamente y se ha convertido en un conjunto de datos de referencia a la hora de analizar el comportamiento de los distintos algoritmos de aprendizaje automático.\n",
    "\n",
    "*Iris* recopila cuatro medidas (longitud y anchura de sépalo y pétalo) de 50 flores de cada una de las siguientes tres especies de lirios: *Iris setosa*, *Iris virginica* e *Iris versicolor*.\n",
    "\n",
    "Los datos se encuentran en el fichero `iris.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dd4ef916",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Longitud sépalo</th>\n",
       "      <th>Anchura sépalo</th>\n",
       "      <th>Longitud pétalo</th>\n",
       "      <th>Anchura pétalo</th>\n",
       "      <th>Especie</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Longitud sépalo  Anchura sépalo  Longitud pétalo  Anchura pétalo  \\\n",
       "0              5.1             3.5              1.4             0.2   \n",
       "1              4.9             3.0              1.4             0.2   \n",
       "2              4.7             3.2              1.3             0.2   \n",
       "3              4.6             3.1              1.5             0.2   \n",
       "4              5.0             3.6              1.4             0.2   \n",
       "\n",
       "       Especie  \n",
       "0  Iris-setosa  \n",
       "1  Iris-setosa  \n",
       "2  Iris-setosa  \n",
       "3  Iris-setosa  \n",
       "4  Iris-setosa  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris = pandas.read_csv('iris.csv', header=None,\n",
    "                       names=['Longitud sépalo', 'Anchura sépalo',\n",
    "                              'Longitud pétalo', 'Anchura pétalo',\n",
    "                              'Especie'])\n",
    "iris.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b7a7336",
   "metadata": {},
   "source": [
    "Se plantea el problema de predecir si una flor es o no de la especie *Iris setosa* a partir de las medidas de sus sépalos y pétalos. Obsérvese que se trata de un problema de clasificación, puesto que la variable objetivo es una variable categórica binaria."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1cb823b",
   "metadata": {},
   "source": [
    "En primer lugar, seleccionamos por un lado las variables predictoras y por otro lado la variable respuesta. En ambos casos transformamos los resultados a un array de NumPy. La variable respuesta la transformamos además a una variable numérica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9a7d995a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.1 3.5 1.4 0.2]\n",
      " [4.9 3.  1.4 0.2]\n",
      " [4.7 3.2 1.3 0.2]\n",
      " ...\n",
      " [6.5 3.  5.2 2. ]\n",
      " [6.2 3.4 5.4 2.3]\n",
      " [5.9 3.  5.1 1.8]]\n"
     ]
    }
   ],
   "source": [
    "atributos = iris.loc[:, 'Longitud sépalo':'Anchura pétalo']\n",
    "atributos = atributos.to_numpy()\n",
    "print(atributos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f2ffa7c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. ... 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "objetivo = iris['Especie'] == 'Iris-setosa'\n",
    "objetivo = objetivo.to_numpy().astype(float)\n",
    "print(objetivo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecdc89da",
   "metadata": {},
   "source": [
    "A continuación construimos los subconjuntos de entrenamiento y prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ebf6b8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "(atributos_entrenamiento, atributos_prueba,\n",
    " objetivo_entrenamiento, objetivo_prueba) = model_selection.train_test_split(\n",
    "    atributos, objetivo, test_size=.33)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d57fd9",
   "metadata": {},
   "source": [
    "Estamos ya en condiciones de construir una red neuronal que nos permita abordar el problema. Al tratarse este de un problema de clasificación binaria es habitual considerar una única neurona de salida que devuelva un valor entre 0 y 1 representando la probabilidad de que el ejemplo de entrada pertenezca a la clase positiva."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6ebaca5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizador = keras.layers.experimental.preprocessing.Normalization()\n",
    "normalizador.adapt(atributos_entrenamiento)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9f451bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "red_lirios = keras.Sequential()\n",
    "red_lirios.add(keras.Input(shape=(4,)))\n",
    "red_lirios.add(normalizador)\n",
    "red_lirios.add(keras.layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "aafb0a5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " normalization_1 (Normalizat  (None, 4)                9         \n",
      " ion)                                                            \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 1)                 5         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14\n",
      "Trainable params: 5\n",
      "Non-trainable params: 9\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "red_lirios.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f1ce080",
   "metadata": {},
   "source": [
    "La función de pérdida a minimizar adecuada en este caso es la entropía cruzada binaria:\n",
    "$$C(y, \\hat{y}) = -y \\log(\\hat{y}) - (1 - y)\\log(1 - \\hat{y})$$\n",
    "donde $y$ es la respuesta correcta e $\\hat{y}$ es la respuesta proporcionada por el modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a4a6b3",
   "metadata": {},
   "source": [
    "También le vamos a pedir a la red que calcule su exactitud, es decir, la fracción de ejemplos clasificados correctamente. Una flor se clasificará como de la especie *Iris setosa* si la probabilidad de que sea así devuelta por la red es mayor que 0.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "81ace11a",
   "metadata": {},
   "outputs": [],
   "source": [
    "red_lirios.compile(optimizer='SGD', loss='binary_crossentropy',\n",
    "                   metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "06808398",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.3124 - accuracy: 0.1800\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.1888 - accuracy: 0.2200\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.0773 - accuracy: 0.2500\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.9770 - accuracy: 0.3100\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.8871 - accuracy: 0.3900\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.8077 - accuracy: 0.4400\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.7378 - accuracy: 0.4900\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6763 - accuracy: 0.5900\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6223 - accuracy: 0.6900\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.5747 - accuracy: 0.7600\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fdf80174160>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "red_lirios.fit(atributos_entrenamiento, objetivo_entrenamiento,\n",
    "               batch_size=10, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a175d626",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5258 - accuracy: 0.8000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5258042216300964, 0.800000011920929]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "red_lirios.evaluate(atributos_prueba, objetivo_prueba)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bcf83b4",
   "metadata": {},
   "source": [
    "En este caso la red construida es capaz de identificar correctamente todas las flores del conjunto de prueba que son de la especie *Iris setosa*. Esto no es sorprendente, ya que es perfectamente conocido que las medidas de los sépalos y pétalos permiten separar esta especie de lirio de las otras dos especies. Separar estas dos últimas entre sí ya entraña un poco de mayor dificultad."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "873afeaf",
   "metadata": {},
   "source": [
    "### **Ejercicio 2**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72bf575c",
   "metadata": {},
   "source": [
    "Se plantea el problema de determinar la especie de lirio a la que pertenece una flor a partir de las medidas de sus sépalos y pétalos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe0acecc",
   "metadata": {},
   "source": [
    "Experimentar con diferentes arquitecturas de redes neuronales y con diferentes configuraciones de entrenamiento para abordar el problema."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b4327ce",
   "metadata": {},
   "source": [
    "Puesto que se trata de un problema de clasificación multiclase, es conveniente que la capa de salida tenga tantas neuronas como clases y que la función de activación para estas neuronas sea la función softmax, que dada la tupla de entradas de las neuronas las normaliza a valores en el intervalo (0, 1) representando la probabilidad de pertenencia a a cada clase:\n",
    "$$\\mathit{softmax}(z_{1}, \\ldots, z_{n}) =\n",
    "\\left(\\frac{\\mathrm{e}^{z_{1}}}{\\sum_{i = 1}^{n} \\mathrm{e}^{z_{i}}}, \\ldots,\n",
    "\\frac{\\mathrm{e}^{z_{n}}}{\\sum_{i = 1}^{n} \\mathrm{e}^{z_{i}}}\\right)$$\n",
    "\n",
    "De esta forma, cada ejemplo se clasificará en la clase más probable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac244cd7",
   "metadata": {},
   "source": [
    "La función de pérdida a minimizar adecuada en este caso es la entropía cruzada categórica (`'categorical_crossentropy'`)\n",
    "$$C(\\mathbf{y}, \\hat{\\mathbf{y}}) = - \\sum_{i = 1}^{n} \\mathbf{y}_{i}⁢ \\log\\hat{\\mathbf{y}}_{i}$$\n",
    "donde $\\mathbf{y}$ es la codificación *one-hot* de la clase correcta e $\\hat{\\mathbf{y}}$ es el vector de probabilidades de pertenencia a cada clase proporcionado por el modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd418eb",
   "metadata": {},
   "source": [
    "Para codificar la variable objetivo mediante *one-hot* es útil la función `get_dummies` de la biblioteca Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9f94de3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Iris-setosa  Iris-versicolor  Iris-virginica\n",
      "0              1                0               0\n",
      "1              1                0               0\n",
      "2              1                0               0\n",
      "3              1                0               0\n",
      "4              1                0               0\n",
      "..           ...              ...             ...\n",
      "145            0                0               1\n",
      "146            0                0               1\n",
      "147            0                0               1\n",
      "148            0                0               1\n",
      "149            0                0               1\n",
      "\n",
      "[150 rows x 3 columns]\n",
      "[[1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " ...\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "objetivo = iris['Especie']\n",
    "objetivo = pandas.get_dummies(objetivo)\n",
    "print(objetivo)\n",
    "objetivo = objetivo.to_numpy()\n",
    "print(objetivo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b8be0db",
   "metadata": {},
   "source": [
    "El objetivo último es construir una red neuronal con una exactitud sobre el conjunto de prueba superior a 0.9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c76b2213",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
